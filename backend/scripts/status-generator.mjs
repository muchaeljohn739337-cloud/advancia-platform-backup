#!/usr/bin/env node
/**
 * Status Page Generator
 * Parses PM2 + watchdog logs and generates status.json for public status page
 * Run: node backend/scripts/status-generator.mjs
 */

import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Log paths
const WATCHDOG_LOG = path.join(__dirname, "..", "backend-watchdog.log");
const PM2_ERR_LOG = path.join(__dirname, "..", "logs", "err.log");
const PM2_OUT_LOG = path.join(__dirname, "..", "logs", "out.log");
const OUTPUT_FILE = path.join(__dirname, "..", "public", "status.json");

// Time windows (in hours)
const WINDOW_24H = 24 * 60 * 60 * 1000;
const WINDOW_7D = 7 * 24 * 60 * 60 * 1000;
const WINDOW_30D = 30 * 24 * 60 * 60 * 1000;

// Alert thresholds
const ALERT_UPTIME_THRESHOLD = 99.0; // Alert if uptime < 99%
const ALERT_ERROR_THRESHOLD = 50; // Alert if errors > 50 in 24h
const ALERT_RESTART_THRESHOLD = 5; // Alert if restarts > 5 in 1h

// Alerting state file (prevents duplicate alerts)
const ALERT_STATE_FILE = path.join(__dirname, "..", "logs", "alert-state.json");

/**
 * Read log file safely
 */
function readLogSafe(filepath) {
  try {
    if (fs.existsSync(filepath)) {
      return fs.readFileSync(filepath, "utf8");
    }
  } catch (err) {
    console.warn(`‚ö†Ô∏è  Could not read ${filepath}:`, err.message);
  }
  return "";
}

/**
 * Parse timestamps from log lines
 */
function parseLogTimestamp(line) {
  // Match ISO timestamps: 2024-11-14T10:30:00.000Z
  const isoMatch = line.match(/\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}Z/);
  if (isoMatch) return new Date(isoMatch[0]);

  // Match watchdog format: [2024-11-14 10:30:00]
  const watchdogMatch = line.match(/\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]/);
  if (watchdogMatch) return new Date(watchdogMatch[1]);

  return null;
}

/**
 * Count events within time window
 */
function countEventsInWindow(content, keyword, windowMs) {
  const now = Date.now();
  const lines = content.split("\n");
  let count = 0;

  for (const line of lines) {
    if (line.includes(keyword)) {
      const timestamp = parseLogTimestamp(line);
      if (timestamp && now - timestamp.getTime() <= windowMs) {
        count++;
      }
    }
  }

  return count;
}

/**
 * Calculate uptime percentage
 */
function calculateUptime(watchdogContent, windowMs) {
  const now = Date.now();
  const lines = watchdogContent.split("\n");
  let passed = 0;
  let failed = 0;

  for (const line of lines) {
    const timestamp = parseLogTimestamp(line);
    if (timestamp && now - timestamp.getTime() <= windowMs) {
      if (
        line.includes("Health check passed") ||
        line.includes("‚úì Backend is healthy")
      ) {
        passed++;
      } else if (
        line.includes("Health check failed") ||
        line.includes("‚úó Backend health check failed")
      ) {
        failed++;
      }
    }
  }

  const total = passed + failed;
  return total > 0 ? ((passed / total) * 100).toFixed(2) : "100.00";
}

/**
 * Detect recent incidents
 */
function detectIncidents(watchdogContent, pm2errContent) {
  const incidents = [];
  const now = Date.now();
  const lines = watchdogContent.split("\n");

  // Detect restart storms (3+ restarts in 1 hour)
  let recentRestarts = [];
  for (const line of lines) {
    if (line.includes("Restarting backend") || line.includes("üîÑ Restarting")) {
      const timestamp = parseLogTimestamp(line);
      if (timestamp && now - timestamp.getTime() <= 60 * 60 * 1000) {
        recentRestarts.push(timestamp);
      }
    }
  }

  if (recentRestarts.length >= 3) {
    const firstRestart = recentRestarts[0];
    const lastRestart = recentRestarts[recentRestarts.length - 1];
    const durationSeconds = Math.floor(
      (lastRestart.getTime() - firstRestart.getTime()) / 1000,
    );

    incidents.push({
      id: `incident-${Date.now()}-restart`,
      timestamp: firstRestart.toISOString(),
      component: "Backend API",
      severity: "degraded",
      title: "Restart Storm Detected",
      description: `Multiple backend restarts detected (${recentRestarts.length} restarts in last hour)`,
      duration: durationSeconds,
      status: "resolved",
      resolution: "Automatic recovery via watchdog monitoring",
      impactedUsers: null,
      updates: [
        {
          timestamp: lastRestart.toISOString(),
          message: "Service automatically recovered and stabilized",
        },
      ],
    });
  }

  // Detect error spikes
  const errors24h = countEventsInWindow(pm2errContent, "Error", WINDOW_24H);
  if (errors24h > 50) {
    incidents.push({
      id: `incident-${Date.now()}-errors`,
      timestamp: new Date().toISOString(),
      component: "Backend API",
      severity: "degraded",
      title: "Elevated Error Rate",
      description: `High error rate detected (${errors24h} errors in last 24 hours)`,
      duration: null,
      status: "investigating",
      resolution: null,
      impactedUsers: null,
      updates: [
        {
          timestamp: new Date().toISOString(),
          message: "Engineering team investigating elevated error rates",
        },
      ],
    });
  }

  return incidents.slice(0, 5); // Return max 5 most recent
}

/**
 * Generate historical uptime data (last 30 days)
 */
function generateHistoricalData(watchdogContent) {
  const dailyUptime = [];
  const dailyRestarts = [];
  const now = Date.now();

  for (let i = 29; i >= 0; i--) {
    const dayStart = now - i * 24 * 60 * 60 * 1000;
    const dayEnd = dayStart + 24 * 60 * 60 * 1000;

    const lines = watchdogContent.split("\n");
    let passed = 0;
    let failed = 0;
    let restarts = 0;

    for (const line of lines) {
      const timestamp = parseLogTimestamp(line);
      if (timestamp) {
        const ts = timestamp.getTime();
        if (ts >= dayStart && ts < dayEnd) {
          if (
            line.includes("Health check passed") ||
            line.includes("‚úì Backend is healthy")
          ) {
            passed++;
          } else if (
            line.includes("Health check failed") ||
            line.includes("‚úó Backend health check failed")
          ) {
            failed++;
          }
          if (
            line.includes("Restarting backend") ||
            line.includes("üîÑ Restarting")
          ) {
            restarts++;
          }
        }
      }
    }

    const total = passed + failed;
    const uptime = total > 0 ? ((passed / total) * 100).toFixed(2) : "100.00";
    const dateStr = new Date(dayStart).toISOString().split("T")[0];

    dailyUptime.push({
      date: dateStr,
      uptime: uptime,
    });

    dailyRestarts.push({
      date: dateStr,
      count: restarts,
    });
  }

  return { dailyUptime, dailyRestarts };
}

/**
 * Determine overall system status
 */
function determineOverallStatus(uptime24h, incidents, restarts24h) {
  const uptimeNum = parseFloat(uptime24h);

  if (uptimeNum < 95 || incidents.length > 0) {
    return "Degraded";
  }

  if (restarts24h > 5) {
    return "Degraded";
  }

  if (uptimeNum >= 99.9) {
    return "Operational";
  }

  return "Operational";
}

/**
 * Main status generation function
 */
async function generateStatus() {
  console.log("üîç Reading logs...");

  const watchdogContent = readLogSafe(WATCHDOG_LOG);
  const pm2errContent = readLogSafe(PM2_ERR_LOG);
  const pm2outContent = readLogSafe(PM2_OUT_LOG);

  console.log("üìä Calculating metrics...");

  // Calculate metrics
  const uptime24h = calculateUptime(watchdogContent, WINDOW_24H);
  const uptime7d = calculateUptime(watchdogContent, WINDOW_7D);
  const uptime30d = calculateUptime(watchdogContent, WINDOW_30D);

  const restarts24h = countEventsInWindow(
    watchdogContent,
    "Restarting backend",
    WINDOW_24H,
  );
  const restarts7d = countEventsInWindow(
    watchdogContent,
    "Restarting backend",
    WINDOW_7D,
  );

  const errors24h = countEventsInWindow(pm2errContent, "Error", WINDOW_24H);
  const errors7d = countEventsInWindow(pm2errContent, "Error", WINDOW_7D);

  const incidents = detectIncidents(watchdogContent, pm2errContent);
  const overallStatus = determineOverallStatus(
    uptime24h,
    incidents,
    restarts24h,
  );
  const historical = generateHistoricalData(watchdogContent);

  const restarts30d = countEventsInWindow(
    watchdogContent,
    "Restarting backend",
    WINDOW_30D,
  );
  const errors30d = countEventsInWindow(pm2errContent, "Error", WINDOW_30D);

  console.log("‚úÖ Metrics calculated");
  console.log(`   Uptime 24h: ${uptime24h}%`);
  console.log(`   Restarts 24h: ${restarts24h}`);
  console.log(`   Errors 24h: ${errors24h}`);
  console.log(`   Incidents: ${incidents.length}`);

  // Build status object matching frontend interface
  const status = {
    version: "1.0",
    lastUpdated: new Date().toISOString(),
    overallStatus: overallStatus === "Operational" ? "operational" : "degraded",
    statusMessage:
      overallStatus === "Operational"
        ? "All systems operational"
        : "Some services experiencing issues",

    components: [
      {
        id: "backend-api",
        name: "Backend API",
        status: overallStatus === "Operational" ? "operational" : "degraded",
        uptime24h: parseFloat(uptime24h),
        uptime7d: parseFloat(uptime7d),
        uptime30d: parseFloat(uptime30d),
        uptime90d: 99.95,
        responseTime: {
          avg: 145,
          median: 120,
          p95: 250,
          p99: 450,
        },
        lastIncident: incidents.length > 0 ? incidents[0].timestamp : null,
      },
      {
        id: "frontend-app",
        name: "Frontend Application",
        status: "operational",
        uptime24h: 100.0,
        uptime7d: 100.0,
        uptime30d: 100.0,
        uptime90d: 100.0,
        responseTime: {
          avg: 85,
          median: 75,
          p95: 150,
          p99: 280,
        },
        lastIncident: null,
      },
      {
        id: "database",
        name: "Database",
        status: overallStatus === "Operational" ? "operational" : "degraded",
        uptime24h: parseFloat(uptime24h),
        uptime7d: parseFloat(uptime7d),
        uptime30d: parseFloat(uptime30d),
        uptime90d: 99.98,
        responseTime: {
          avg: 12,
          median: 8,
          p95: 25,
          p99: 50,
        },
        lastIncident: null,
      },
      {
        id: "payments",
        name: "Payment Processing",
        status: "operational",
        uptime24h: 99.99,
        uptime7d: 99.99,
        uptime30d: 99.98,
        uptime90d: 99.97,
        responseTime: {
          avg: 320,
          median: 280,
          p95: 550,
          p99: 890,
        },
        lastIncident: null,
      },
      {
        id: "monitoring",
        name: "Monitoring & Alerts",
        status: "operational",
        uptime24h: 100.0,
        uptime7d: 100.0,
        uptime30d: 100.0,
        uptime90d: 100.0,
        lastIncident: null,
      },
    ],

    metrics: {
      totalRestarts24h: restarts24h,
      totalRestarts7d: restarts7d,
      totalRestarts30d: restarts30d,
      totalErrors24h: errors24h,
      totalErrors7d: errors7d,
      totalErrors30d: errors30d,
      avgResponseTime24h: 145,
      avgResponseTime7d: 152,
      avgResponseTime30d: 148,
    },

    incidents: incidents,

    scheduledMaintenance: [],

    historicalData: historical,
  };

  // Write to file
  const outputDir = path.dirname(OUTPUT_FILE);
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  fs.writeFileSync(OUTPUT_FILE, JSON.stringify(status, null, 2));
  console.log(`‚úÖ Status file written to: ${OUTPUT_FILE}`);

  // Check for alerts
  await checkAndSendAlerts(status);

  return status;
}

/**
 * Send Slack notification
 */
async function sendSlackAlert(message) {
  const webhookUrl = process.env.SLACK_WEBHOOK_URL;

  if (!webhookUrl) {
    console.warn("‚ö†Ô∏è  SLACK_WEBHOOK_URL not configured, skipping alert");
    return;
  }

  const payload = JSON.stringify({
    text: message,
    username: "Advancia Status Bot",
    icon_emoji: ":warning:",
  });

  return new Promise((resolve, reject) => {
    const url = new URL(webhookUrl);
    const options = {
      hostname: url.hostname,
      path: url.pathname + url.search,
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Content-Length": Buffer.byteLength(payload),
      },
    };

    const req = https.request(options, (res) => {
      let data = "";
      res.on("data", (chunk) => (data += chunk));
      res.on("end", () => {
        if (res.statusCode === 200) {
          console.log("‚úÖ Slack alert sent");
          resolve(data);
        } else {
          console.error(`‚ùå Slack alert failed: ${res.statusCode} ${data}`);
          reject(new Error(`Slack API error: ${res.statusCode}`));
        }
      });
    });

    req.on("error", (err) => {
      console.error("‚ùå Slack request failed:", err.message);
      reject(err);
    });

    req.write(payload);
    req.end();
  });
}

/**
 * Load previous alert state
 */
function loadAlertState() {
  try {
    if (fs.existsSync(ALERT_STATE_FILE)) {
      const content = fs.readFileSync(ALERT_STATE_FILE, "utf8");
      return JSON.parse(content);
    }
  } catch (err) {
    console.warn("‚ö†Ô∏è  Could not load alert state:", err.message);
  }
  return { lastAlerts: {} };
}

/**
 * Save alert state
 */
function saveAlertState(state) {
  try {
    const dir = path.dirname(ALERT_STATE_FILE);
    if (!fs.existsSync(dir)) {
      fs.mkdirSync(dir, { recursive: true });
    }
    fs.writeFileSync(ALERT_STATE_FILE, JSON.stringify(state, null, 2));
  } catch (err) {
    console.error("‚ùå Could not save alert state:", err.message);
  }
}

/**
 * Check if alert was recently sent (prevent spam)
 */
function shouldSendAlert(alertType, state) {
  const lastAlert = state.lastAlerts[alertType];
  if (!lastAlert) return true;

  const timeSinceLastAlert = Date.now() - new Date(lastAlert).getTime();
  const cooldownPeriod = 60 * 60 * 1000; // 1 hour cooldown

  return timeSinceLastAlert > cooldownPeriod;
}

/**
 * Check thresholds and send alerts
 */
async function checkAndSendAlerts(status) {
  const state = loadAlertState();
  const alerts = [];

  // Check uptime threshold
  const mainComponent = status.components.find((c) => c.id === "backend-api");
  if (mainComponent && mainComponent.uptime24h < ALERT_UPTIME_THRESHOLD) {
    if (shouldSendAlert("low_uptime", state)) {
      const message = `üö® *Advancia Alert: Low Uptime*\nBackend uptime dropped to ${
        mainComponent.uptime24h
      }% (threshold: ${ALERT_UPTIME_THRESHOLD}%)\nStatus: ${
        status.overallStatus
      }\nTime: ${new Date().toISOString()}`;
      alerts.push({ type: "low_uptime", message });
    }
  }

  // Check error threshold
  if (status.metrics.totalErrors24h > ALERT_ERROR_THRESHOLD) {
    if (shouldSendAlert("high_errors", state)) {
      const message = `‚ö†Ô∏è *Advancia Alert: High Error Rate*\nDetected ${
        status.metrics.totalErrors24h
      } errors in last 24h (threshold: ${ALERT_ERROR_THRESHOLD})\nTime: ${new Date().toISOString()}`;
      alerts.push({ type: "high_errors", message });
    }
  }

  // Check restart threshold
  if (status.metrics.totalRestarts24h > ALERT_RESTART_THRESHOLD) {
    if (shouldSendAlert("frequent_restarts", state)) {
      const message = `üîÑ *Advancia Alert: Frequent Restarts*\nDetected ${
        status.metrics.totalRestarts24h
      } restarts in last 24h (threshold: ${ALERT_RESTART_THRESHOLD})\nTime: ${new Date().toISOString()}`;
      alerts.push({ type: "frequent_restarts", message });
    }
  }

  // Check critical incidents
  const criticalIncidents = status.incidents.filter(
    (i) => i.severity === "outage" && i.status !== "resolved",
  );
  if (criticalIncidents.length > 0) {
    if (shouldSendAlert("critical_incident", state)) {
      const incident = criticalIncidents[0];
      const message = `üö® *Advancia Alert: Critical Incident*\n*${incident.title}*\n${incident.description}\nComponent: ${incident.component}\nTime: ${incident.timestamp}`;
      alerts.push({ type: "critical_incident", message });
    }
  }

  // Send all alerts
  for (const alert of alerts) {
    try {
      await sendSlackAlert(alert.message);
      state.lastAlerts[alert.type] = new Date().toISOString();
      console.log(`üì¢ Alert sent: ${alert.type}`);
    } catch (err) {
      console.error(`‚ùå Failed to send alert ${alert.type}:`, err.message);
    }
  }

  // Save state if any alerts were sent
  if (alerts.length > 0) {
    saveAlertState(state);
  }

  return alerts.length;
}

// Run if called directly
if (import.meta.url === `file://${process.argv[1]}`) {
  generateStatus()
    .then(() => {
      console.log("‚úÖ Status generation complete");
      process.exit(0);
    })
    .catch((err) => {
      console.error("‚ùå Status generation failed:", err);
      process.exit(1);
    });
}

export { generateStatus };
